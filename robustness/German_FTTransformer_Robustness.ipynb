{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hungd\\anaconda3\\envs\\fair-ai-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Optional\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from aif360.sklearn.datasets import fetch_german\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Data Loading and Preparation\n",
    "# ---------------------------\n",
    "X, y = fetch_german()\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Binarize labels\n",
    "y = y.map({'good': 1, 'bad': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary_age column based on the condition, value = aged if age >= 25 else young\n",
    "X['age_group'] = X['age'].apply(lambda x: 'aged' if x >= 25 else 'young')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_enc = X.copy()\n",
    "cat_cols = X_enc.select_dtypes(['object','category']).columns\n",
    "cardinalities = []\n",
    "label_mappings = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_enc[col] = le.fit_transform(X_enc[col])\n",
    "    cardinalities.append(len(le.classes_))\n",
    "    label_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "num_cols = [c for c in X_enc.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cardinalities of categorical columns: [4, 5, 10, 5, 5, 3, 4, 3, 3, 4, 2, 2, 2, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCardinalities of categorical columns: {cardinalities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_enc, y, test_size=0.1, random_state=7\n",
    ")\n",
    "\n",
    "# Convert to numpy / tensors\n",
    "X_train_num = X_train[num_cols].to_numpy(dtype=np.float32)\n",
    "X_test_num  = X_test[num_cols].to_numpy(dtype=np.float32)\n",
    "X_train_cat = X_train[cat_cols].to_numpy(dtype=np.int64)\n",
    "X_test_cat  = X_test[cat_cols].to_numpy(dtype=np.int64)\n",
    "y_train_np = y_train.astype(np.int64).values if isinstance(y_train, pd.Series) else y_train.astype(np.int64)\n",
    "y_test_np = y_test.astype(np.int64).values if isinstance(y_test, pd.Series) else y_test.astype(np.int64)\n",
    "\n",
    "X_train_num_t = torch.from_numpy(X_train_num)\n",
    "X_train_cat_t = torch.from_numpy(X_train_cat)\n",
    "X_test_num_t = torch.from_numpy(X_test_num)\n",
    "X_test_cat_t = torch.from_numpy(X_test_cat)\n",
    "\n",
    "y_train_t = torch.from_numpy(y_train_np)\n",
    "y_test_t  = torch.from_numpy(y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTTransformer(\n",
       "  (cls_embedding): _CLSEmbedding()\n",
       "  (cont_embeddings): LinearEmbeddings()\n",
       "  (cat_embeddings): CategoricalEmbeddings(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(4, 32)\n",
       "      (1): Embedding(5, 32)\n",
       "      (2): Embedding(10, 32)\n",
       "      (3-4): 2 x Embedding(5, 32)\n",
       "      (5): Embedding(3, 32)\n",
       "      (6): Embedding(4, 32)\n",
       "      (7-8): 2 x Embedding(3, 32)\n",
       "      (9): Embedding(4, 32)\n",
       "      (10-12): 3 x Embedding(2, 32)\n",
       "      (13): Embedding(4, 32)\n",
       "      (14): Embedding(2, 32)\n",
       "    )\n",
       "  )\n",
       "  (backbone): FTTransformerBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_normalization): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (linear1): Linear(in_features=32, out_features=84, bias=True)\n",
       "          (activation): _ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=42, out_features=32, bias=True)\n",
       "        )\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "      )\n",
       "      (1-2): 2 x ModuleDict(\n",
       "        (attention): MultiheadAttention(\n",
       "          (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ffn_normalization): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (linear1): Linear(in_features=32, out_features=84, bias=True)\n",
       "          (activation): _ReGLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=42, out_features=32, bias=True)\n",
       "        )\n",
       "        (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output): Identity()\n",
       "        (attention_normalization): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output): Sequential(\n",
       "      (normalization): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation): ReLU()\n",
       "      (linear): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rtdl_revisiting_models import FTTransformer\n",
    "\n",
    "# Input dims\n",
    "d_num = X_train_num.shape[1]\n",
    "cat_cardinalities = cardinalities\n",
    "n_cont_features = len(num_cols)\n",
    "d_out = 2\n",
    "\n",
    "default_kwargs = FTTransformer.get_default_kwargs()\n",
    "# default_kwargs['n_blocks'] = 2\n",
    "default_kwargs['d_block'] = 32\n",
    "default_kwargs['attention_n_heads'] = 1\n",
    "# default_kwargs['attention_dropout'] = 0.2   # originally ~0.1\n",
    "# default_kwargs['ffn_dropout']       = 0.2   # originally ~0.05\n",
    "# default_kwargs['ffn_residual_dropout']  = 0.05   # originally 0.0\n",
    "# default_kwargs['residual_dropout']  = 0.05   # originally 0.0 or tiny\n",
    "\n",
    "model = FTTransformer(\n",
    "    n_cont_features=n_cont_features,\n",
    "    cat_cardinalities=cat_cardinalities,\n",
    "    d_out=d_out,\n",
    "    **default_kwargs,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hungd\\AppData\\Local\\Temp\\ipykernel_7676\\3117073470.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"saved_model/fttransformer_german.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model.load_state_dict(torch.load(\"saved_model/fttransformer_german.pth\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "X_test_num_t = X_test_num_t.to(device)\n",
    "X_test_cat_t = X_test_cat_t.to(device)\n",
    "y_test_t  = y_test_t .to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_num_t, X_test_cat_t)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "    accuracy = (preds == y_test_t).float().mean().item()\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.metrics import clever_u, loss_sensitivity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_comb = np.concatenate([X_train_num, X_train_cat], axis=1)\n",
    "X_test_comb  = np.concatenate([X_test_num,  X_test_cat ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "clip_values = (X_test_comb.min(), X_test_comb.max())\n",
    "\n",
    "num_samples = X_test_comb.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedFT(nn.Module):\n",
    "    def __init__(self, ft_model, d_num):\n",
    "        super().__init__()\n",
    "        self.ft = ft_model\n",
    "        self.d_num = d_num\n",
    "    def forward(self, x):\n",
    "        # x: torch.Tensor of shape (n, d_num + d_cat)\n",
    "        x = x.to(torch.float32)\n",
    "        x_num = x[:, : self.d_num]\n",
    "        x_cat = x[:, self.d_num :].to(torch.long)\n",
    "        return self.ft(x_num, x_cat)\n",
    "\n",
    "combined_model = CombinedFT(model, d_num).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier for TabResNet\n",
    "art_classifier = PyTorchClassifier(\n",
    "    model=combined_model,\n",
    "    loss=criterion,\n",
    "    input_shape=(X_train_comb.shape[1],),\n",
    "    nb_classes=2,\n",
    "    optimizer=optimizer,\n",
    "    clip_values=clip_values,\n",
    "    device_type=device\n",
    ")\n",
    "\n",
    "# Train the ART classifier with TabResNet\n",
    "# art_classifier.fit(X_train_np, y_train_np, batch_size=64, nb_epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuraacy Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign accuracy:           0.8000\n",
      "Adversarial accuracy:      0.7900\n",
      "Accuracy gap (benign–adv): 0.0100\n"
     ]
    }
   ],
   "source": [
    "# 5) Evaluate on benign examples\n",
    "preds_benign = art_classifier.predict(X_test_comb)\n",
    "acc_benign = accuracy_score(y_test, np.argmax(preds_benign, axis=1))\n",
    "print(f\"Benign accuracy:           {acc_benign:.4f}\")\n",
    "\n",
    "# 6) Generate & evaluate adversarial\n",
    "attack = FastGradientMethod(estimator=art_classifier, eps=0.3)\n",
    "X_test_adv = attack.generate(X_test_comb)\n",
    "preds_adv = art_classifier.predict(X_test_adv)\n",
    "acc_adv = accuracy_score(y_test, np.argmax(preds_adv, axis=1))\n",
    "print(f\"Adversarial accuracy:      {acc_adv:.4f}\")\n",
    "print(f\"Accuracy gap (benign–adv): {acc_benign - acc_adv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEVER-u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clever-u Score:\n",
    "\n",
    "score is a lower bound -> minimum perturbation size required to change the model's output to any wrong label\n",
    "\n",
    "“directional probes” (here 10*20=200) -> to get a reliable worst‐case slope estimate\n",
    "\n",
    "A higher score -> stronger local robustness\n",
    "\n",
    "range value = [0.0, radius]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLEVER-U samples: 100%|██████████| 100/100 [00:05<00:00, 19.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CLEVER-U:             0.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clever_scores = []\n",
    "for x in tqdm(X_test_comb, desc=\"CLEVER-U samples\"):\n",
    "    c = clever_u(\n",
    "        classifier=art_classifier,\n",
    "        x=x,\n",
    "        nb_batches=20,\n",
    "        batch_size=1,\n",
    "        norm=2,\n",
    "        radius=0.2,\n",
    "        verbose=False\n",
    "    )\n",
    "    clever_scores.append(c)\n",
    "print(f\"Mean CLEVER-U:             {np.mean(clever_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Sensitivity\n",
    "\n",
    "A **higher** sensitivity -> small input perturbations can cause **larger** changes in the loss -> indicating a \"steeper\" or potentially **less** robust local region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss sensitivity:     0.004076\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "# Convert integer labels to one-hot:\n",
    "y_test_onehot = np.eye(num_classes)[y_test_np]\n",
    "\n",
    "ls = loss_sensitivity(\n",
    "    classifier=art_classifier,\n",
    "    x=X_test_comb,\n",
    "    y=y_test_onehot\n",
    ")\n",
    "print(f\"Mean loss sensitivity:     {np.mean(ls):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ww-ihnSUcCz2",
    "8PJTcdufcCz8",
    "fu9sqMIgcCz-",
    "J22g3WEccC0I",
    "9TMwzwvNcC0K",
    "GfVfYd_ZcC0Q",
    "UgJ9XJAWDev3",
    "7N5q_LeLyo4x",
    "67Vzn6iuYS2q",
    "538PskKGALFU",
    "VJ0Mb-gM8lHj",
    "ki-IgGuwcC0k",
    "WeKnka-4W8Wr"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fair-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
